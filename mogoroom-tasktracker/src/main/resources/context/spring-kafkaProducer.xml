<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:int="http://www.springframework.org/schema/integration"
	xmlns:int-kafka="http://www.springframework.org/schema/integration/kafka"
	xmlns:task="http://www.springframework.org/schema/task"
	xsi:schemaLocation="http://www.springframework.org/schema/integration/kafka http://www.springframework.org/schema/integration/kafka/spring-integration-kafka.xsd
		http://www.springframework.org/schema/integration http://www.springframework.org/schema/integration/spring-integration.xsd
		http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
		http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task.xsd">

	<int:publish-subscribe-channel id="inputToKafka" />

	<int-kafka:outbound-channel-adapter
		id="kafkaOutboundChannelAdapter" kafka-producer-context-ref="kafkaProducerContext"
		auto-startup="true" order="1" channel="inputToKafka" />
		
	<int-kafka:producer-context id="kafkaProducerContext"
		producer-properties="producerProps">
		<int-kafka:producer-configurations>
			<int-kafka:producer-configuration
				broker-list="${sysconfig.kafka.broker-list}" 
				topic="${sysconfig.kafka.topic}" key-class-type="java.lang.String" key-encoder="encoder"
				value-class-type="java.lang.String" value-encoder="encoder"
				  />
		</int-kafka:producer-configurations>
	</int-kafka:producer-context>

	<bean id="producerProps" class="org.springframework.beans.factory.config.PropertiesFactoryBean">
		<property name="properties">
			<props>
				<!-- 在producer queue的缓存的数据最大时间 -->
				<prop key="queue.buffering.max.ms">500</prop>
				<!-- 定期的获取元数据的时间。当分区丢失，leader不可用时producer也会主动获取元数据，如果为0，则每次发送完消息就获取元数据，不推荐。如果为负值，则只有在失败的情况下获取元数据。 -->
				<prop key="topic.metadata.refresh.interval.ms">3600000</prop>
				<!-- 在异步模式下，producer端允许buffer的最大消息数量，如果producer无法尽快将消息发送给broker，从而导致消息在producer端大量沉积，如果消息的条数达到此配置值，将会导致producer端阻塞或者消息被抛弃。 -->
				<prop key="queue.buffering.max.messages">10000</prop>
				<!-- 在每次重发之前，producer会刷新相关的topic的元数据，来看看是否选出了一个新leader。由于选举leader会花一些时间，此选项指定了在刷新元数据前等待的时间 -->
				<prop key="retry.backoff.ms">100</prop>
				<!-- 如果producer发送消息失败了会自动重发，本选项指定了重发的次数。注意如果是非0值，那么可能会导致重复发送，就是说的确发送了消息，但是没有收到ack，那么就还会发一次。 -->
				<prop key="message.send.max.retries">2</prop>
				<!-- socket的发送缓存大小。 -->
				<prop key="send.buffer.bytes">5242880</prop>
				<!-- socket请求的最大数值，防止serverOOM，message.max.bytes必然要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖 -->
				<prop key="socket.request.max.bytes">104857600</prop>
				<!-- socket的接受缓冲区，socket的调优参数SO_RCVBUFF -->
				<prop key="socket.receive.buffer.bytes">1048576</prop>
				<!-- socket的发送缓冲区，socket的调优参数SO_SNDBUFF -->
				<prop key="socket.send.buffer.bytes">1048576</prop>
				<!-- 用来控制一个produce请求怎样才能算完成，准确的说，是有多少broker必须已经提交数据到log文件，并向leader发送ack，可以设置如下的值 -->
				<!-- 0，意味着producer永远不会等待一个来自broker的ack，这就是0.7版本的行为。这个选项提供了最低的延迟，但是持久化的保证是最弱的，当server挂掉的时候会丢失一些数据。
1，意味着在leader replica已经接收到数据后，producer会得到一个ack。这个选项提供了更好的持久性，因为在server确认请求成功处理后，client才会返回。如果刚写到leader上，还没来得及复制leader就挂了，那么消息才可能会丢失。
-1，意味着在所有的ISR都接收到数据后，producer才得到一个ack。这个选项提供了最好的持久性，只要还有一个replica存活，那么数据就不会丢失。 -->
				<prop key="request.required.acks">1</prop>
			</props>
		</property>
	</bean>

	<bean id="encoder"
		class="org.springframework.integration.kafka.serializer.common.StringEncoder" />


	<task:executor id="taskExecutor" pool-size="5"
		keep-alive="120" queue-capacity="500" />

</beans>